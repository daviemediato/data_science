{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Corretor Ortográfico\n",
    "\n",
    "Neste `notebook` vamos implementar um corretor ortográfico utilizando `python` e princípios de linguagem natural.\n",
    "\n",
    "## O que é um corretor ortográfico?\n",
    "\n",
    "Um corretor ortográfico se baseia na correção de eventuais erros de escrita de determinadas palavras digitadas.\n",
    "\n",
    "## Como funciona o corretor ortográfico?\n",
    "\n",
    "O corretor ortográfico irá comparar a palavra em questão com as palavras de uma base de dados - `dicionário` - onde tais palavras tem-se a certeza que estão corretas. Assim, a palavra é aceita se a mesma se encontra presente no dicionário, caso contrário, o corretor irá propor uma palavra com escrita esperada. Assim, tem-se o seguinte exemplo:\n",
    "\n",
    "    Um usuário digita a palavra: lgica.\n",
    "    O corretor devolve a palavra: lógica.\n",
    "    \n",
    "### Quais são os erros mais comuns?\n",
    "\n",
    "Sabendo quais são os erros gramaticais mais comuns, podemos traçar estratégias para começar a implementar o corretor ortográfico em questão. Podemos, então, pensar na palavra `lógica`:\n",
    "\n",
    "- Esquecer de digitar uma letra: `lógic`\n",
    "- Escrever uma letra a mais: `lógicaa`\n",
    "- Inverter a posição de uma letra: `lóigca`\n",
    "- Escrever uma letra errada: `légica`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importações\n",
    "\n",
    "Aqui utilizaremos as seguintes bibliotecas para o projeto:\n",
    "\n",
    "- [nltk](https://www.nltk.org/) : é uma biblioteca em python utilizada para tratamento de dados em linguagem natural.\n",
    "- [typing](https://docs.python.org/3/library/typing.html) : é um modulo que provoca melhorias de dicas de tipagem."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Caso você precise instalar a biblioteca nltk descomente a linha abaixo:\n",
    "\n",
    "# pip install nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\Davi\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Tuple"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Nossa base de dados\n",
    "\n",
    "Como foi dito, iremos utilizar uma base de dados para representar nosso \"dicionário\", ou seja, nosso vocabulário."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "imagem \n",
      "\n",
      "Temos a seguinte classe que representa um usuário no nosso sistema:\n",
      "\n",
      "java\n",
      "\n",
      "Para salvar um novo usuário, várias validações são feitas, como por exemplo: Ver se o nome só contém letras, [**o CPF só números**] e ver se o usuário possui no mínimo 18 anos. Veja o método que faz essa validação:\n",
      "\n",
      "java \n",
      "\n",
      "Suponha agora que eu tenha outra classe, a classe `Produto`, que contém um atributo nome e eu quero fazer a mesma validação que fiz para o nome do usuário: Ver se só contém letras. E aí? Vou\n"
     ]
    }
   ],
   "source": [
    "with open('../datasets/artigos.txt', mode='r', encoding='utf8') as f:\n",
    "    artigos = f.read()\n",
    "    \n",
    "print(artigos[:500])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## O que se observa\n",
    "\n",
    "Percebe-se que ao exibir a variável artigos todas as palavras se encontram juntas. Assim, é necessário separa-lás, já que queremos analisar individualmente cada uma, como sendo um único elemento de um `array` (e não uma `string` gigante). Também, queremos obter apenas os caracteres `alpha` (letras entre a-z).\n",
    "\n",
    "## O processo de Tokenização\n",
    "\n",
    "\n",
    "A tokenização, também conhecida como segmentação de palavras, irá quebrar a sequência de caracteres em um texto localizando o limite de cada palavra, ou seja, os pontos onde uma palavra termina e outra começa. Assim, sendo necessário realizar a separação das palavras, será utilizado a função `tokenize.word_tokenize` da biblioteca `nltk`. Entretanto, em alguns casos, teremos palavras:\n",
    "\n",
    "    por que; porque?; onde; onde,;\n",
    "    \n",
    "É necessário, portanto, retirar aqueles elementos que possuem caracteres fora do escopo das letras `A-Z`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['imagem',\n",
       " 'Temos',\n",
       " 'a',\n",
       " 'seguinte',\n",
       " 'classe',\n",
       " 'que',\n",
       " 'representa',\n",
       " 'um',\n",
       " 'usuário',\n",
       " 'no']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def separa_palavras(lista_tokens: list) -> list:\n",
    "    \"\"\"\n",
    "        Recebe uma lista de tokens e retorna uma lista filtrada apenas com tokens sem caracteres de pontuação.\n",
    "        \n",
    "        lista_tokens: é a lista de tokens geradas por meio do word_tokezine.\n",
    "    \"\"\"\n",
    "    \n",
    "    # É a lista de palavras sem caracteres de pontuação\n",
    "    lista_palavras = []\n",
    "    \n",
    "    # Percorro minha lista de tokens\n",
    "    for token in lista_tokens:\n",
    "        # Verifico se o token é totalmente alpha (A-Z)\n",
    "        if token.isalpha():\n",
    "            # Insiro na lista de palavras\n",
    "            lista_palavras.append(token)\n",
    "    \n",
    "    # Retorno a lista de palavras\n",
    "    return lista_palavras\n",
    "\n",
    "# Crio uma lista de tokens com a variável artigos\n",
    "lista_tokens = nltk.tokenize.word_tokenize(artigos)\n",
    "\n",
    "# Crio uma lista de palavras, apenas que possuem A-Z, removendo caracteres de pontuação (?,.;!)\n",
    "lista_palavras = separa_palavras(lista_tokens)\n",
    "\n",
    "# Exibição\n",
    "lista_palavras[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Normalização \n",
    "\n",
    "Ainda falta realizarmos alguns tratamentos na nossa base de dados, entre tais, se encontra o processo de normalização. Isso significa criarmos um padrão entre nossos dados, ou seja, como aqui estamos tratando com palavras, uma boa maneira é transforma-lás todas em minúsculas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['são',\n",
       " 'feitas',\n",
       " 'como',\n",
       " 'por',\n",
       " 'exemplo',\n",
       " 'ver',\n",
       " 'se',\n",
       " 'o',\n",
       " 'nome',\n",
       " 'só',\n",
       " 'contém',\n",
       " 'letras',\n",
       " 'o',\n",
       " 'cpf',\n",
       " 'só',\n",
       " 'números',\n",
       " 'e',\n",
       " 'ver',\n",
       " 'se',\n",
       " 'o']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def normalizacao(lista_palavras: list) -> list:\n",
    "    \"\"\"\n",
    "        Recebe uma lista de palavras e retorna uma lista padronizada com todas as palavras em minúsculo.\n",
    "        \n",
    "        lista_palavras: é a lista de palavras após a retirada de caracteres fora de A-Z.\n",
    "    \"\"\"\n",
    "    # É a lista normalizada\n",
    "    lista_normalizada = []\n",
    "    \n",
    "    # Percorro a lista de palavras\n",
    "    for palavra in lista_palavras:\n",
    "        # Insiro o conteúdo em minúsculo\n",
    "        lista_normalizada.append(palavra.lower())\n",
    "    \n",
    "    # Retorno a lista normalizada\n",
    "    return lista_normalizada\n",
    "\n",
    "# Crio minha lista normalizada\n",
    "lista_normalizada = normalizacao(lista_palavras)\n",
    "\n",
    "# Exibição\n",
    "lista_normalizada[20:40]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Desenvolvendo o corretor ortográfico\n",
    "\n",
    "O primeiro passo para desenvolver o corretor ortográfico é desenvolver as `funções auxiliares`. Como foi abordado, iremos criar uma função para os principais erros encontrados.\n",
    "\n",
    "## Primeiro erro: a falta de uma letra.\n",
    "\n",
    "A ideia de corrigir uma palavra que possui uma letra faltante é justamente inserir letras para `completar` o que falta. Assim, podemos pensar na palavra `lóica` e separa-lá em duas metades - `esquerda` e `direita` -. Para nós é nítido que devemos inserir a letra `g` entre as fatias de `ló` e `ica`.\n",
    "    \n",
    "    parte esquerda + letra faltante + parte direita"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['lóaica', 'lóbica', 'lócica', 'lóeica', 'lódica', 'lófica', 'lógica']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def insere_letras(fatias: list) -> list:\n",
    "    \"\"\"\n",
    "        Recebe uma lista de tuplas '(lado esquerdo, lado direito)' que corresponde aos lados de uma palavra fatiada em dois.\n",
    "        Retorna possíveis palavras corretas com letras inseridas.\n",
    "        \n",
    "        fatias: uma tupla formada com o lado esquerdo e direito de uma palavra dividida.\n",
    "    \"\"\"\n",
    "    # São as possíveis novas palavras\n",
    "    novas_palavras = []\n",
    "    \n",
    "    # Todas as letras do alfabeto\n",
    "    letras = 'abcedfghijklmnopqrstuvwxyzáâàãéêèíîìóôòõúûùç'\n",
    "    \n",
    "    # Percorro a lista de fatias\n",
    "    for esquerdo, direito in fatias:\n",
    "        # Percorro todas as letras\n",
    "        for letra in letras:\n",
    "            # Insiro uma letra entre os lados esquerdo e direito de uma fatia\n",
    "            novas_palavras.append(esquerdo + letra + direito)\n",
    "    \n",
    "    # Retorno as possíveis palavras após inserir todo alfabeto\n",
    "    return novas_palavras\n",
    "\n",
    "# Crio um exemplo\n",
    "exemplo = insere_letras([('ló', 'ica')])\n",
    "\n",
    "# Exibição\n",
    "exemplo[:7]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Segundo erro: uma letra a mais\n",
    "\n",
    "A ideia de corrigir uma palavra que possui uma letra a mais é justamente `remover` uma letra da palavra em questão. Podemos pensar na palavra `lógicaa`. É nítido que a letra `a` foi escrita mais de uma vez. Assim a ideia continua em dividir em fatias e lados - esquerdo e direito -. Entretanto, sempre iremos remover a primeira posição da fatia a direita."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['lógica']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def remove_letras(fatias: list) -> list:\n",
    "    \"\"\"\n",
    "        Recebe uma lista de tuplas '(lado esquerdo, lado direito)' que corresponde aos lados de uma palavra fatiada em dois.\n",
    "        Retorna possíveis palavras corretas com letras removidas.\n",
    "        \n",
    "        fatias: uma tupla formada com o lado esquerdo e direito de uma palavra dividida.\n",
    "    \"\"\"\n",
    "    \n",
    "    # As novas palavras\n",
    "    novas_palavras = []\n",
    "    \n",
    "    # Percorro lista de fatias\n",
    "    for esquerdo, direito in fatias:\n",
    "        # Insiro a palavra com o lado direito sem a sua primeira posição\n",
    "        novas_palavras.append(esquerdo + direito[1:])\n",
    "    \n",
    "    # Retorno as possíveis palavras após remover as letras\n",
    "    return novas_palavras\n",
    "\n",
    "# Crio um exemplo\n",
    "exemplo = remove_letras([('lógic', 'aa')])\n",
    "\n",
    "# Exibição\n",
    "exemplo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Terceiro erro: trocando as letras\n",
    "\n",
    "Esse também é um erro bastante comum e a ideia é justamente `trocar` a letra errada pela letra correta. Um exemplo nítido para se observar tal comportamento é tem-se a palavra `lógeca`, assim, a ideia é obter a troca de `e` por `i`.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['lógaca',\n",
       " 'lógbca',\n",
       " 'lógcca',\n",
       " 'lógeca',\n",
       " 'lógdca',\n",
       " 'lógfca',\n",
       " 'lóggca',\n",
       " 'lóghca',\n",
       " 'lógica',\n",
       " 'lógjca']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def troca_letras(fatias: list) -> list:\n",
    "    \"\"\"\n",
    "        Recebe uma lista de tuplas '(lado esquerdo, lado direito)' que corresponde aos lados de uma palavra fatiada em dois.\n",
    "        Retorna possíveis palavras corretas com letras trocadas.\n",
    "        \n",
    "        fatias: uma tupla formada com o lado esquerdo e direito de uma palavra dividida.\n",
    "    \"\"\"\n",
    "    \n",
    "    # São as possíveis novas palavras\n",
    "    novas_palavras = []\n",
    "    \n",
    "    # Todas as letras do alfabeto\n",
    "    letras = 'abcedfghijklmnopqrstuvwxyzáâàãéêèíîìóôòõúûùç'\n",
    "    \n",
    "    # Percorro a lista de fatias\n",
    "    for esquerdo, direito in fatias:\n",
    "        # Percorro todas as letras\n",
    "        for letra in letras:\n",
    "            # Insiro uma possível letra correta no lugar da letra errada\n",
    "            novas_palavras.append(esquerdo + letra + direito[1:])\n",
    "    \n",
    "    # Retorno as possíveis palavras após trocar todo alfabeto\n",
    "    return novas_palavras\n",
    "\n",
    "# Crio um exemplo\n",
    "exemplo = troca_letras([('lóg', 'eca')])\n",
    "\n",
    "# Exibição\n",
    "exemplo[:10]\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Quarto erro: invertendo uma letra\n",
    "\n",
    "Esse erro é um exemplo de quando queremos escrever a palavra `lógica` mas escrevemos `lógcia`, ou seja, invertemos a letra `i` pela `c`. Isso pode ser concertado com a mesma ideia de fatias, entretanto, trocamos as posições das letras de `index 0` com `index 1` da fatia direita."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['lógica']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def inverte_letras(fatias: list) -> list:\n",
    "    \"\"\"\n",
    "        Recebe uma lista de tuplas '(lado esquerdo, lado direito)' que corresponde aos lados de uma palavra fatiada em dois.\n",
    "        Retorna possíveis palavras corretas com letras invertidas.\n",
    "        \n",
    "        fatias: uma tupla formada com o lado esquerdo e direito de uma palavra dividida.\n",
    "    \"\"\"\n",
    "    \n",
    "    # As novas palavras\n",
    "    novas_palavras = []\n",
    "    \n",
    "    # Percorro lista de fatias\n",
    "    for esquerdo, direito in fatias:\n",
    "        # Insiro a palavra invertendo as posições do lado direito caso o tamanho seja > 1\n",
    "        if len(direito) > 1:\n",
    "            novas_palavras.append(esquerdo + direito[1] + direito[0] + direito[2:])\n",
    "    \n",
    "    # Retorno as possíveis palavras após inverter as letras\n",
    "    return novas_palavras\n",
    "\n",
    "# Crio um exemplo\n",
    "exemplo = inverte_letras([('lógi', 'ac')])\n",
    "\n",
    "# Exibição\n",
    "exemplo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# O Corretor Ortográfico\n",
    "\n",
    "A ideia básica do corretor ortográfico é justamente gerar diversas palavras que podem ser uma possível palavra correta. Sendo assim, temos que ter ainda mais funções auxiliares."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gerador de Palavras\n",
    "\n",
    "Vamos criar uma função que irá gerar \"palavras separadas\" dada uma palavra em questão. Aqui abordaremos as fatias, sendo esta uma lista composta por tuplas (lado esquerdo, lado direito) da palavra."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['alógicaa',\n",
       " 'blógicaa',\n",
       " 'clógicaa',\n",
       " 'elógicaa',\n",
       " 'dlógicaa',\n",
       " 'flógicaa',\n",
       " 'glógicaa',\n",
       " 'hlógicaa',\n",
       " 'ilógicaa',\n",
       " 'jlógicaa']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def gerador_palavras(palavra: str)-> list:\n",
    "    \"\"\"\n",
    "        Recebe uma palavra.\n",
    "        Retorna possíveis palavras, dentre elas está a palavra correta.\n",
    "        \n",
    "        palavra: uma string.\n",
    "    \"\"\"\n",
    "    \n",
    "    # É a lista de fatias\n",
    "    fatias = []\n",
    "    \n",
    "    # É o tamanho da palavra + 1\n",
    "    tamanho = len(palavra) + 1\n",
    "\n",
    "    # Gero as possiveis fatias de uma palavra, sendo esta uma lista de tuplas (esquerdo, direito)\n",
    "    for i in range(tamanho):\n",
    "        fatias.append((palavra[:i], palavra[i:]))\n",
    "\n",
    "    # Crio possiveis palavras de acordo com os possíveis erros abordados\n",
    "    palavras_geradas = insere_letras(fatias) + remove_letras(fatias) + troca_letras(fatias) + inverte_letras(fatias)\n",
    "    \n",
    "    # Retorno as possíveis palavras, dentre elas está a palavra correta\n",
    "    return palavras_geradas\n",
    "\n",
    "# Crio um exemplo\n",
    "exemplo = gerador_palavras('lógicaa')\n",
    "\n",
    "# Exibição\n",
    "exemplo[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Algumas constantes\n",
    "\n",
    "Aqui iremos definir algumas constantes que serão utilizadas no decorrer do final do procedimento do corretor e sua avaliação"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# É necessário obter as frequencias de cada palavra, assim vamos utilizar FreqDist da nltk\n",
    "frequencia = nltk.FreqDist(lista_normalizada)\n",
    "\n",
    "# É nececessário obter o total de palavras\n",
    "total_palavras = len(lista_normalizada)\n",
    "\n",
    "# Total de palavras diferentes, é o nosso vocabulario sem palavras repetidas\n",
    "vocabulario = set(lista_normalizada)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Probabilidade\n",
    "\n",
    "Como estamos criando diversas palavras devemos escolher um critério para avaliar a probabilidade daquela palavra gerada ser a correta."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def probabilidade(palavra_gerada: str) -> int:\n",
    "    \"\"\"\n",
    "        Recebe uma palavra.\n",
    "        Retorna a probabilidade daquela palavra estar presente no vocabulario.\n",
    "        \n",
    "        palavra_gerada: uma string.\n",
    "    \"\"\"\n",
    "    # Calcula a probabilidade da palavra gerada estar em nosso vocabulário\n",
    "    probabilidade = frequencia[palavra_gerada]/total_palavras\n",
    "    \n",
    "    # Retorna um inteiro representando a probabilidade\n",
    "    return probabilidade"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Enfim... o corretor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'automático'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def corretor(palavra: str) -> str:\n",
    "    \"\"\"\n",
    "        Recebe uma palavra.\n",
    "        Retorna a palavra correta.\n",
    "        \n",
    "        palavra: uma string.\n",
    "    \"\"\"\n",
    "\n",
    "    # A partir de uma palavra irei gerar possiveis palavras corretas\n",
    "    palavras_geradas = gerador_palavras(palavra)\n",
    "\n",
    "    # Busco a palavra correta a partir da que possui maior probabilidade, utilizo aqui a função max\n",
    "    palavra_correta = max(palavras_geradas, key=probabilidade)\n",
    "    \n",
    "    # Retorno a palavra correta\n",
    "    return palavra_correta\n",
    "\n",
    "# Crio um exemplo\n",
    "exemplo = corretor('automtico')\n",
    "\n",
    "# Exibição\n",
    "exemplo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Avaliando o corretor ortográfico\n",
    "\n",
    "Por fim, iremos avaliar o nosso corretor por meio de uma base de teste. Assim, iremos criar mais algumas funções auxiliares."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cria_dados_teste(nome_arquivo: str) -> list:\n",
    "    \"\"\"\n",
    "        Recebe o nome do arquivo referente as palavras a serem testadas.\n",
    "        Retorna uma lista de palavras para o teste em si e sua avaliação.\n",
    "        \n",
    "        nome_arquivo: uma string.\n",
    "    \"\"\"\n",
    "    # É a lista de palavras para o teste\n",
    "    lista_palavras_teste = []\n",
    "\n",
    "    # Aqui abro o arquivo\n",
    "    f = open(nome_arquivo, mode='r', encoding='utf8')\n",
    "\n",
    "    # Em cada linha do arquivo f\n",
    "    for linha in f:\n",
    "        # Splito a linha com a palavra correta e a errada\n",
    "        correta, errada = linha.split()\n",
    "        # Adiciono como sendo uma tupla na lista\n",
    "        lista_palavras_teste.append((correta, errada))\n",
    "\n",
    "    # Fecho o arquivo\n",
    "    f.close()\n",
    "\n",
    "    # Retorno a lista de tuplas com as palavras certas e erradas\n",
    "    return lista_palavras_teste"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def avaliador(testes: list, vocabulario: list) -> Tuple[int, int]:\n",
    "    \"\"\"\n",
    "        Recebe uma lista de testes e o vocabulário do problema.\n",
    "        Retorna a porcentagem de palavras acertadas e a porcentagem de palavras desconhecidas.\n",
    "        \n",
    "        palavra: uma string.\n",
    "    \"\"\"\n",
    "    # Número de palavras totais presente no teste\n",
    "    numero_palavras = len(testes)\n",
    "    \n",
    "    # Quantidade de acerto\n",
    "    acertou = 0\n",
    "    \n",
    "    # Quantidade desconhecida\n",
    "    desconhecida = 0\n",
    "    \n",
    "    \n",
    "    # Percorro os testes\n",
    "    for correta, errada in testes:\n",
    "        # Chamo o corretor com a palavra errada a ser corrigida\n",
    "        palavra_corrigida = corretor(errada)\n",
    "        # Verifico se a palavra correta existe no vocabulario\n",
    "        desconhecida += (correta not in vocabulario)\n",
    "\n",
    "        # Se a palavra corrigida for igual a correta, temos um acerto\n",
    "        if palavra_corrigida == correta:\n",
    "            acertou += 1\n",
    "\n",
    "    # Porcentagem de palavras conhecidas\n",
    "    taxa_acerto = round(acertou*100/numero_palavras, 2)\n",
    "\n",
    "    # Porcentagem de palavras desconhecidas\n",
    "    taxa_desconhecida = round(desconhecida*100/numero_palavras, 2)\n",
    "    \n",
    "    # Retorno a taxa de acerto do corretor ortográfico e a taxa de palavras deconhecidas\n",
    "    return taxa_acerto, taxa_desconhecida"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('podemos', 'pyodemos'),\n",
       " ('esse', 'esje'),\n",
       " ('já', 'jrá'),\n",
       " ('nosso', 'nossov'),\n",
       " ('são', 'sãêo'),\n",
       " ('dos', 'dosa'),\n",
       " ('muito', 'muifo'),\n",
       " ('imagem', 'iômagem'),\n",
       " ('sua', 'ósua'),\n",
       " ('também', 'tambéùm')]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Crio a lista dos testes\n",
    "lista_teste = cria_dados_teste('../datasets/palavras.txt')\n",
    "\n",
    "# Exibição\n",
    "lista_teste[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A taxa de acerto é de 76.34 % e a taxa de palavras desconhecidas é de 6.99 %\n"
     ]
    }
   ],
   "source": [
    "# Chamo a avaliação\n",
    "taxa_a, taxa_e = avaliador(lista_teste, vocabulario)\n",
    "\n",
    "# Exibo\n",
    "print(f'A taxa de acerto é de {taxa_a} % e a taxa de palavras desconhecidas é de {taxa_e} %')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fique a vontade...\n",
    "\n",
    "Se quiser brincar um pouco com o corretor, rs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Entrada =================> anial\n",
      "Resposta do corretor ==> animal\n"
     ]
    }
   ],
   "source": [
    "# Digite aqui a sua palavra incorreta\n",
    "teste = 'anial'\n",
    "\n",
    "# Mostrando as respostas do corretor\n",
    "print(f'Entrada =================> {teste}\\nResposta do corretor ==> {corretor(teste)}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
